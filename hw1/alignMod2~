#!/usr/bin/env python                                                                             
import optparse
import sys
from collections import defaultdict

optparser = optparse.OptionParser()
optparser.add_option("-d", "--data", dest="train", default="data/hansards", help="Data filename prefix (default=data)")
optparser.add_option("-e", "--english", dest="english", default="e", help="Suffix of English filename (default=e)")
optparser.add_option("-f", "--french", dest="french", default="f", help="Suffix of French filename (default=f)")
optparser.add_option("-t", "--threshold", dest="threshold", default=0.5, type="float", help="Threshold for aligning with Dice's coefficient (default=0.5)")
optparser.add_option("-n", "--num_sentences", dest="num_sents", default=sys.maxint, type="int", help="Number of sentences to use for training and alignment")
optparser.add_option( "--outFileEToF", dest="eToF", default='eToFMod2.a', help="Name of output file for alignment English to French")
optparser.add_option("--outFileFToE", dest="fToE", default='fToEMod2.a', help="Name of output file for alignment French to English")
(opts, _) = optparser.parse_args()
f_data = "%s.%s" % (opts.train, opts.french)
e_data = "%s.%s" % (opts.train, opts.english)

fVocab = set()
eVocab = set()

#create an array of tuples, each containing one sentence pair                                     
bitext = [[(pair[0]).lower().strip().split(), (pair[1]).split()] for pair in zip(open(e_data), open(f_data))[:opts.num_sents]]
#get the unique set of words for each language                                                    
for (e, f)  in bitext:
  for word in set(f):
    fVocab.add(word)
  for word in set(e):
    eVocab.add(word)

#the size of each vocabulary                                                                       
sizeF = len(fVocab)
sizeE = len(eVocab)

#TRANSLATION ALIGNMENT FROM FRENCH TO ENGLISH                                                      
t_ef = defaultdict(int)
fe_count = defaultdict(int)
total = defaultdict(int)
sTotal = defaultdict(int)
#Initialize t_ef uniformly                                                                        
for (e, f) in bitext:
  for e_i in set(e):
    for f_j in set(f):
      t_ef[e_i,f_j] = 1.0 / sizeE
sys.stderr.write("Aligning from French to English\n")
#while not converged                                                                               
i = 0
while i < 5:
  i += 1
  sys.stderr.write("initializing totals and counts\n")
  for (e, f) in bitext:
    #initializing the totals and the counts                                                        
    for e_i in set(e):
      for f_j in set(f):
        fe_count[e_i,f_j] = 0.0
  for f_j in fVocab:
    total[f_j] = 0.0
  #compute the normalization                                                                       
  sys.stderr.write("computing normalization and collecting counts\n")
  for (e, f) in bitext:
    for e_i in set(e):
      sTotal[e_i] = 0.0
      for f_j in set(f):
        sTotal[e_i] += t_ef[e_i,f_j]
    #collect counts                   
    for e_i in set(e):
      for f_j in set(f):
        fe_count[e_i,f_j] += t_ef[e_i,f_j] / sTotal[e_i]
        total[f_j] += t_ef[e_i,f_j] / sTotal[e_i]
  #estimate probabilities                                                                          
  for k, (e, f) in enumerate(bitext):
    if k % 500 == 0:
      sys.stderr.write(".")
    for f_j in (f):
      for e_i in (e):
        t_ef[e_i, f_j] = fe_count[e_i, f_j] / total[f_j]
  sys.stderr.write("\nend of iteration %i\n"% (i - 1))

sys.stderr.write("Writing model 1 to file\n")
temp = sys.stdout
sys.stdout = file("fToEMod1.a", 'w')
for k, (e, f) in enumerate(bitext):
  lf = len(set(e))
  le = len(set(e))
  if k % 500 == 0:
    sys.stderr.write(">")
  for (j, e_j) in enumerate(e):
    for (i, f_i) in enumerate(f):
      if t_ef[e_j, f_i] >= 0.28:
        sys.stdout.write("%i-%i " % (i,j))
  sys.stdout.write("\n")
sys.stderr.write("\n")
sys.stdout.close()
sys.stdout = temp

sys.stderr.write("Starting model 2\n")
#Initialize a(i|j,le, lf) 
a = defaultdict(int)
for (e, f) in bitext: 
  lf = len(set(f))
  for i, f_i in enumerate(f):
    for j, e_j in enumerate(e):
      a[i, j, len(set(e)), lf] = 1.0 / (lf + 1)
fe_count.clear()
sTotal.clear()
total.clear()
count_A = defaultdict(int)
total_A = defaultdict(int)
k = 0
while k < 5:
  k += 1
  sys.stderr.write("Initializing the totals and the counts\n")
  for (e, f) in bitext:
    le = len(set(e))
    lf = len(set(f))
    #initializing the totals and the counts                                                        
    for j, e_j in enumerate(e):
      for i, f_i in enumerate(f):
        fe_count[e_j,f_i] = 0.0
        total[f_i] = 0.0
        count_A[i, j, le, lf] = 0.0
        total_A[j, le, lf] = 0.0 
  sys.stderr.write("Computing normalization\n")
  for (e, f) in bitext: 
    le = len(set(e))
    lf = len(set(f)) 
    #compute normalization
    for j, e_j in enumerate(e): 
      sTotal[e_j] = 0.0 
      for i, f_i in enumerate(f):
        sTotal[e_j] += t_ef[e_j, f_i] * a[i, j, le, lf]
    for j, e_j in enumerate(e): 
      for i, f_i in enumerate(f): 
        c = t_ef[e_j,f_i] * a[i, j, le, lf] / sTotal[e_j]
        fe_count[e_j, f_i] += c
        total[f_i] += c
        count_A[i, j, le, lf] += c
        total_A[j, le, lf] += c
  #estimate probabilities
  sys.stderr.write("Estimating prbabilities\n")
  for (e, f) in bitext:
    for j, e_j in enumerate(e):
      for i, f_i in enumerate(f):
        t_ef[e_j,f_i] = 0.0
        a[i, j, len(set(e)), len(set(f))]
  for (e, f) in bitext: 
    for e_j in set(e):
      for f_i in set(f): 
        t_ef[e_j, f_i] = fe_count[e_j,f_i] / total[f_i]
  for (e, f) in bitext: 
    le = len(set(e))
    lf = len(set(f))
    for j, e_j in enumerate(e):
      for i, f_i in enumerate(f): 
        a[i, j, le, lf] = count_A[i, j, le, lf] / total_A[j, le, lf] 
  sys.stderr.write("\nend of iteration %i\n"% (k - 1))

sys.stderr.write("Writing model 2 to file\n")
temp = sys.stdout
sys.stdout = file(opts.fToE, 'w')
for k, (e, f) in enumerate(bitext):
  lf = len(set(e))
  le = len(set(e))
  if k % 500 == 0:
    sys.stderr.write(">")
  for (j, e_j) in enumerate(e):
    for (i, f_i) in enumerate(f):
      if t_ef[e_j, f_i] >= 0.28:
        sys.stdout.write("%i-%i " % (i,j))
  sys.stdout.write("\n")
sys.stderr.write("\n")
sys.stdout.close()
sys.stdout = temp

#TRANSLATION FROM ENGLISH TO FRENCH
bitext = [[((pair[0]).lower().strip()[:pair[0].find(" ")] + (pair[0]).lower().strip()[pair[0].find(" "):]).split(), (pair[1]).lower().strip().split()] for pair in zip(open(e_data), open(f_data))[:opts.num_sents]]
t_fe = defaultdict(int)
ef_count = defaultdict(int)
totalEF = defaultdict(int)
sTotalEF = defaultdict(int)
#Initialize t_ef uniformly                                                                        
for (e, f) in bitext:
  for f_j in set(f):
    for e_i in set(e):
      t_fe[f_j,e_i] = 1.0 / sizeF
sys.stderr.write("Aligning from English to French\n")
#while not converged                                                                               
i = 0
while i < 5:
  i += 1
  sys.stderr.write("initializing totals and counts\n")
  for (e, f) in bitext:
    #initializing the totals and the counts                                                        
    for f_j in set(f):
      for e_i in set(e):
        ef_count[f_j,e_i] = 0.0
  for e_i in eVocab:
    totalEF[e_i] = 0.0
  #compute the normalization                                                                       
  sys.stderr.write("computing normalization and collecting counts\n")
  for (e, f) in bitext:
    for f_j in set(f):
      sTotalEF[f_j] = 0.0
      for e_i in set(e):
        sTotalEF[f_j] += t_fe[f_j,e_i]
    #collect counts                   
    for f_j in set(f):
      for e_i in set(e):
        ef_count[f_j,e_i] += t_fe[f_j,e_i] / sTotalEF[f_j]
        totalEF[e_i] += t_fe[f_j,e_i] / sTotalEF[f_j]
  #estimate probabilities                                                                          
  for k, (e, f) in enumerate(bitext):
    if k % 500 == 0:
      sys.stderr.write(".")
    for f_j in (f):
      for e_i in (e):
        t_fe[f_j,e_i] = ef_count[f_j, e_i] / totalEF[e_i]
  sys.stderr.write("\nend of iteration %i\n"% (i - 1))

sys.stderr.write("Writing model 1 to file\n")
temp = sys.stdout
sys.stdout = file("eToFMod1.a", 'w')
for k, (e, f) in enumerate(bitext):
  lf = len(set(e))
  le = len(set(e))
  if k % 500 == 0:
    sys.stderr.write(">")
  for (j, e_j) in enumerate(e):
    for (i, f_i) in enumerate(f):
      if t_ef[e_j, f_i] >= 0.28:
        sys.stdout.write("%i-%i " % (i,j))
  sys.stdout.write("\n")
sys.stderr.write("\n")
sys.stdout.close()
sys.stdout = temp

sys.stderr.write("Starting model 2\n")
#Initialize a(i|j,le, lf) 
a = defaultdict(int)
for (e, f) in bitext: 
  lf = len(set(f))
  le = len(set(e))
  for j, e_j in enumerate(e):
    for i, f_i in enumerate(f):
      a[j, i, lf, le] = 1.0 / (le + 1)
ef_count.clear()
sTotalEF.clear()
totalEF.clear()
count_A = defaultdict(int)
total_A = defaultdict(int)
k = 0
while k < 5:
  k += 1
  sys.stderr.write("Initializing the totals and the counts\n")
  for (e, f) in bitext:
    le = len(set(e))
    lf = len(set(f))
    #initializing the totals and the counts                                                        
    for i, f_i in enumerate(f):
      for j, e_j in enumerate(e):
        ef_count[f_i, e_j] = 0.0
        totalEF[e_j] = 0.0
        count_A[j, i, lf, le] = 0.0
        total_A[i, lf, le] = 0.0 
  sys.stderr.write("Computing the normalization\n")
  for (e, f) in bitext: 
    le = len(set(e))
    lf = len(set(f)) 
    #compute normalization
    for i, f_i in enumerate(f): 
      sTotalEF[f_i] = 0.0 
      for j, e_j in enumerate(e):
        sTotalEF[f_i] += t_fe[f_i, e_j] * a[j, i, lf, le]
    for i, f_i in enumerate(f):
      for j, e_j in enumerate(e):
        c = t_fe[f_i,e_j] * a[j, i, lf, le] / sTotalEF[f_i]
        ef_count[f_i, e_j] += c
        totalEF[e_j] += c
        count_A[j, i, lf, le] += c
        total_A[i, lf, le] += c
  #estimate probabilities
  sys.stderr.write("Estimating probabilities\n")
  for (e, f) in bitext:
    for i, f_i in enumerate(f):
      for j, e_j in enumerate(e):
        t_fe[f_i, e_j] = 0.0
        a[j, i, len(set(f)), len(set(e))]
  for (e, f) in bitext: 
    for f_i in set(f):
      for e_j in set(e): 
        t_fe[f_i, e_j] = ef_count[f_i, e_j] / totalEF[e_j]
  for (e, f) in bitext: 
    le = len(set(e))
    lf = len(set(f))
    for i, f_i in enumerate(f):
      for j, e_j in enumerate(e):
        a[j, i, lf, le] = count_A[j, i, lf, le] / total_A[i, lf, le] 
  sys.stderr.write("End of iteration #%i\n" % (k - 1))

sys.stderr.write("Writing model 2 to file\n")

temp = sys.stdout
sys.stdout = file(opts.eToF, 'w')
for k, (e, f) in enumerate(bitext):
  lf = len(set(e))
  le = len(set(e))
  if k % 500 == 0:
    sys.stderr.write(">")
  for (i, f_i) in enumerate(f):
    for (j, e_j) in enumerate(e):
      if t_fe[f_i, e_j] >= 0.28:
        sys.stdout.write("%i-%i " % (i,j))
  sys.stdout.write("\n")
sys.stderr.write("\n")
sys.stdout.close()
sys.stdout = temp
